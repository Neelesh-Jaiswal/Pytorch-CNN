{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\Downloads\\Ineuron\\deep_learning_project\\CNN_Pytorch_implementation_13_MARCH\\Pytorch-CNN\\env\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this notebook is using device: cpu\n"
     ]
    }
   ],
   "source": [
    "class Config:\n",
    "  def __init__(self):\n",
    "    self.ROOT_DATA_DIR = \"FashionMNISTDir\"\n",
    "    self.EPOCH = 10\n",
    "    self.BATCH_SIZE = 32\n",
    "    self.LEARNING_RATE = 0.01\n",
    "    self.IMAGE_SIZE = (28, 28)\n",
    "    self.DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(f\"this notebook is using device: {self.DEVICE}\")\n",
    "    self.SEED = 2022\n",
    "\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.FashionMNIST(\n",
    "    root = config.ROOT_DATA_DIR,\n",
    "    train = True,\n",
    "    download = True,\n",
    "    transform = transforms.ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root = config.ROOT_DATA_DIR,\n",
    "    train = False,\n",
    "    download = True,\n",
    "    transform = transforms.ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'T-shirt/top': 0,\n",
       " 'Trouser': 1,\n",
       " 'Pullover': 2,\n",
       " 'Dress': 3,\n",
       " 'Coat': 4,\n",
       " 'Sandal': 5,\n",
       " 'Shirt': 6,\n",
       " 'Sneaker': 7,\n",
       " 'Bag': 8,\n",
       " 'Ankle boot': 9}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "given_label_map = train_data.class_to_idx\n",
    "given_label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'T-shirt/top',\n",
       " 1: 'Trouser',\n",
       " 2: 'Pullover',\n",
       " 3: 'Dress',\n",
       " 4: 'Coat',\n",
       " 5: 'Sandal',\n",
       " 6: 'Shirt',\n",
       " 7: 'Sneaker',\n",
       " 8: 'Bag',\n",
       " 9: 'Ankle boot'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map = {val: key for key, val in given_label_map.items()}\n",
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader = DataLoader(\n",
    "    dataset = train_data,\n",
    "    batch_size = config.BATCH_SIZE,\n",
    "    shuffle = True\n",
    ")\n",
    "\n",
    "test_data_loader = DataLoader(\n",
    "    dataset = test_data,\n",
    "    batch_size = config.BATCH_SIZE,\n",
    "    shuffle = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "for images, labels in train_data_loader:\n",
    "  print(images.shape)\n",
    "  print(labels.shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "  def __init__(self, in_, out_):\n",
    "    super(CNN, self).__init__()\n",
    "\n",
    "    self.conv_pool_01 = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=in_, out_channels=8, kernel_size=5, stride=1, padding=0),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "    )\n",
    "\n",
    "    self.conv_pool_02 = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=8, out_channels=16, kernel_size=5, stride=1, padding=0),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "    )\n",
    "\n",
    "    self.Flatten = nn.Flatten()\n",
    "    self.FC_01 = nn.Linear(in_features=16*4*4, out_features=128)\n",
    "    self.FC_02 = nn.Linear(in_features=128, out_features=64)\n",
    "    self.FC_03 = nn.Linear(in_features=64, out_features=out_)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.conv_pool_01(x)\n",
    "    x = self.conv_pool_02(x)\n",
    "    x = self.Flatten(x)\n",
    "    x = self.FC_01(x)\n",
    "    x = F.relu(x)\n",
    "    x = self.FC_02(x)\n",
    "    x = F.relu(x)    \n",
    "    x = self.FC_03(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv_pool_01): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv_pool_02): Sequential(\n",
      "    (0): Conv2d(8, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (Flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (FC_01): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (FC_02): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (FC_03): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = CNN(1, 10)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_3a2d1_\">\n",
       "  <caption>Total parameters: {'trainable': 45226, 'non_trainable': 0}</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >Modules</th>\n",
       "      <th class=\"col_heading level0 col1\" >Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_3a2d1_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_3a2d1_row0_col0\" class=\"data row0 col0\" >conv_pool_01.0.weight</td>\n",
       "      <td id=\"T_3a2d1_row0_col1\" class=\"data row0 col1\" >200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3a2d1_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_3a2d1_row1_col0\" class=\"data row1 col0\" >conv_pool_01.0.bias</td>\n",
       "      <td id=\"T_3a2d1_row1_col1\" class=\"data row1 col1\" >8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3a2d1_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_3a2d1_row2_col0\" class=\"data row2 col0\" >conv_pool_02.0.weight</td>\n",
       "      <td id=\"T_3a2d1_row2_col1\" class=\"data row2 col1\" >3200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3a2d1_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_3a2d1_row3_col0\" class=\"data row3 col0\" >conv_pool_02.0.bias</td>\n",
       "      <td id=\"T_3a2d1_row3_col1\" class=\"data row3 col1\" >16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3a2d1_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_3a2d1_row4_col0\" class=\"data row4 col0\" >FC_01.weight</td>\n",
       "      <td id=\"T_3a2d1_row4_col1\" class=\"data row4 col1\" >32768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3a2d1_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_3a2d1_row5_col0\" class=\"data row5 col0\" >FC_01.bias</td>\n",
       "      <td id=\"T_3a2d1_row5_col1\" class=\"data row5 col1\" >128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3a2d1_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_3a2d1_row6_col0\" class=\"data row6 col0\" >FC_02.weight</td>\n",
       "      <td id=\"T_3a2d1_row6_col1\" class=\"data row6 col1\" >8192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3a2d1_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_3a2d1_row7_col0\" class=\"data row7 col0\" >FC_02.bias</td>\n",
       "      <td id=\"T_3a2d1_row7_col1\" class=\"data row7 col1\" >64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3a2d1_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_3a2d1_row8_col0\" class=\"data row8 col0\" >FC_03.weight</td>\n",
       "      <td id=\"T_3a2d1_row8_col1\" class=\"data row8 col1\" >640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3a2d1_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_3a2d1_row9_col0\" class=\"data row9 col0\" >FC_03.bias</td>\n",
       "      <td id=\"T_3a2d1_row9_col1\" class=\"data row9 col1\" >10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x11a37b42148>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_params(model):\n",
    "  model_params = {\"Modules\": list(), \"Parameters\": list()}\n",
    "  total = {\"trainable\": 0, \"non_trainable\": 0} \n",
    "  for name, parameters in model.named_parameters():\n",
    "    param = parameters.numel()\n",
    "    if not parameters.requires_grad:\n",
    "      total[\"non_trainable\"] += param\n",
    "      continue\n",
    "    model_params[\"Modules\"].append(name)\n",
    "    model_params[\"Parameters\"].append(param)\n",
    "    total[\"trainable\"] += param\n",
    "  df = pd.DataFrame(model_params)\n",
    "  df = df.style.set_caption(f\"Total parameters: {total}\")\n",
    "  return df\n",
    "\n",
    "count_params(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss() ## loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config.LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████████| 1875/1875 [00:27<00:00, 68.10it/s, loss=0.718]\n",
      "Epoch 2/10: 100%|██████████████| 1875/1875 [00:28<00:00, 65.04it/s, loss=0.376]\n",
      "Epoch 3/10: 100%|██████████████| 1875/1875 [00:31<00:00, 59.79it/s, loss=0.595]\n",
      "Epoch 4/10: 100%|██████████████| 1875/1875 [00:33<00:00, 55.49it/s, loss=0.235]\n",
      "Epoch 5/10: 100%|██████████████| 1875/1875 [00:47<00:00, 39.77it/s, loss=0.302]\n",
      "Epoch 6/10: 100%|██████████████| 1875/1875 [00:41<00:00, 44.72it/s, loss=0.148]\n",
      "Epoch 7/10: 100%|██████████████| 1875/1875 [00:41<00:00, 44.81it/s, loss=0.346]\n",
      "Epoch 8/10: 100%|██████████████| 1875/1875 [00:38<00:00, 48.13it/s, loss=0.297]\n",
      "Epoch 9/10: 100%|██████████████| 1875/1875 [00:43<00:00, 43.53it/s, loss=0.588]\n",
      "Epoch 10/10: 100%|█████████████| 1875/1875 [00:40<00:00, 46.06it/s, loss=0.351]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(config.EPOCH):\n",
    "  with tqdm(train_data_loader) as tqdm_epoch:\n",
    "    for images, labels in tqdm_epoch:\n",
    "      tqdm_epoch.set_description(f\"Epoch {epoch + 1}/{config.EPOCH}\")\n",
    "\n",
    "      # put the images on device\n",
    "      images = images.to(config.DEVICE)\n",
    "      labels = labels.to(config.DEVICE)\n",
    "\n",
    "      # forward pass\n",
    "      outputs = model(images)\n",
    "      loss = criterion(outputs, labels) # TODO #<< passing the pred, target\n",
    "\n",
    "      # backward prop\n",
    "      optimizer.zero_grad() # past gradient\n",
    "      loss.backward() # calculate the gradients\n",
    "      optimizer.step() # weights updated\n",
    "\n",
    "      tqdm_epoch.set_postfix(loss=loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
